{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evan6007/ResNet/blob/main/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcI4ts0cR7kI",
        "outputId": "9a5c7474-e0e6-417a-e4ec-3a5e93479236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU or CPU for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4msh_7CR_xs"
      },
      "outputs": [],
      "source": [
        "class block(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
        "    ):\n",
        "        super(block, self).__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels * self.expansion,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
        "        self.layer1 = self._make_layer(\n",
        "            block, layers[0], intermediate_channels=64, stride=1\n",
        "        )\n",
        "        self.layer2 = self._make_layer(\n",
        "            block, layers[1], intermediate_channels=128, stride=2\n",
        "        )\n",
        "        self.layer3 = self._make_layer(\n",
        "            block, layers[2], intermediate_channels=256, stride=2\n",
        "        )\n",
        "        self.layer4 = self._make_layer(\n",
        "            block, layers[3], intermediate_channels=512, stride=2\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
        "        identity_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "        # to the layer that's ahead\n",
        "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
        "            identity_downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels,\n",
        "                    intermediate_channels * 4,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(intermediate_channels * 4),\n",
        "            )\n",
        "\n",
        "        layers.append(\n",
        "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
        "        )\n",
        "\n",
        "        # The expansion size is always 4 for ResNet 50,101,152\n",
        "        self.in_channels = intermediate_channels * 4\n",
        "\n",
        "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "        # and also same amount of channels.\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            layers.append(block(self.in_channels, intermediate_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "def ResNet101(img_channel=3, num_classes=2):\n",
        "    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvXDxSixSC0Y"
      },
      "outputs": [],
      "source": [
        "model = ResNet101()\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR_iPlP3SEem",
        "outputId": "40ebd498-7416-4a61-e8fb-cdb15142f8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data_faces’: File exists\n",
            "fatal: destination path 'ResNet' already exists and is not an empty directory.\n",
            "--2022-03-27 13:24:59--  https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\n",
            "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.193.80\n",
            "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.193.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1443490838 (1.3G) [application/zip]\n",
            "Saving to: ‘celeba.zip’\n",
            "\n",
            "celeba.zip          100%[===================>]   1.34G  21.1MB/s    in 68s     \n",
            "\n",
            "2022-03-27 13:26:08 (20.3 MB/s) - ‘celeba.zip’ saved [1443490838/1443490838]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#如果載過可以先\"\"\"起來\n",
        "\n",
        "!mkdir data_faces #建設一個資料夾來放需要的資料集\n",
        "!git clone https://github.com/evan6007/ResNet.git\n",
        "!wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip #如果覺得太慢可以直接去網址下載#\n",
        "with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref: #解壓縮\n",
        "    zip_ref.extractall(\"data_faces/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmE9UPsGSKG7"
      },
      "outputs": [],
      "source": [
        "img_list = os.listdir('data_faces/img_align_celeba') #celeba總共有202599張照片\n",
        "print(len(img_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOL-ZxsgSoUt"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"list_attr_celeba.csv\") #這個csv要自己去網路上下載https://www.kaggle.com/jessicali9530/celeba-dataset\n",
        "df = df[['image_id','Smiling']] #csv裡面有包含很多照片的訊息，只取照片id跟是否有笑\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAQ1ByaVSqVd"
      },
      "outputs": [],
      "source": [
        "#建立資料夾\n",
        "!mkdir data\n",
        "!mkdir data/smile\n",
        "!mkdir data/no_smile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJgQ7Hs4S2GF"
      },
      "outputs": [],
      "source": [
        "#這次訓練只用有笑1500張,不笑1500張\n",
        "num = 1500\n",
        "num_smile,num_nosmile=0,0\n",
        "\n",
        "#開始把照片分開放到不同資料夾\n",
        "for i, (_, i_row) in enumerate(df.iterrows()):\n",
        "    if num_smile < num:\n",
        "        if i_row['Smiling'] == 1:\n",
        "            num_smile += 1\n",
        "            shutil.copyfile('data_faces/img_align_celeba/' + i_row['image_id'],\n",
        "                            'data/smile/' + i_row['image_id'])\n",
        "    if num_nosmile < num:\n",
        "        if i_row['Smiling'] == -1:\n",
        "            num_nosmile += 1\n",
        "            shutil.copyfile('data_faces/img_align_celeba/' + i_row['image_id'],\n",
        "                            'data/no_smile/' + i_row['image_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnigE2QqS4vd"
      },
      "outputs": [],
      "source": [
        "!rm -rf 'data/.ipynb_checkpoints/' #刪除checkpoints,避免再修正完程式碼後有沒有刪的東西"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oogBI-uS6L1"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "celeba_data = datasets.ImageFolder('data',transform=transform)\n",
        "\n",
        "print(celeba_data.classes)\n",
        "print(len(celeba_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hZYHEv2S6mg"
      },
      "outputs": [],
      "source": [
        "img_list = os.listdir('data/smile')    #先把照片的數量存起來\n",
        "img_list.extend(os.listdir('data/no_smile'))\n",
        "print(\"Images: \",len(img_list))\n",
        "\n",
        "train_size = int(len(img_list)*0.75)  #訓練集為75%\n",
        "test_size = len(img_list) - train_size #測試集為100%-75%也就是25%\n",
        "\n",
        "train_set, test_set = torch.utils.data.random_split(celeba_data,[train_size, test_size]) #開始分訓練集跟測試集\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True) #打包成64組一包\n",
        "testLoader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True) #打包成64組一包\n",
        "\n",
        "print(train_size) #訓練集的張數\n",
        "print(test_size) #訓練集的張數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z09N4tdfS6-1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001) #設定優化器\n",
        "criterion = nn.CrossEntropyLoss() #設定loss函數\n",
        "epochs = 20  #設定迭代次數\n",
        "train_loss = []\n",
        "\n",
        "\n",
        "model.train() #要訓練就要先開啟訓練模式\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    total_train_loss = 0\n",
        "    \n",
        "    for idx,(image,label) in enumerate(trainLoader):\n",
        "        image, label = image.to(device), label.to(device)\n",
        "        \n",
        "        #################################  pytorch的訓練都幾乎這樣寫\n",
        "        optimizer.zero_grad()           #\n",
        "        pred = model(image)             #\n",
        "                                        #\n",
        "        loss = criterion(pred,label)    #\n",
        "        total_train_loss += loss.item() #\n",
        "                                        #\n",
        "        loss.backward()                 #\n",
        "        optimizer.step()                #\n",
        "        #################################\n",
        "        \n",
        "    total_train_loss = total_train_loss / (idx+1)\n",
        "    train_loss.append(total_train_loss) #把loss存起來 等等才能畫出來\n",
        "    print(f'Epoch: {epoch} | Train Loss: {total_train_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuNDhh6eS7A5"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-Rnu1A6S7DG"
      },
      "outputs": [],
      "source": [
        "#製作測試集\n",
        "testiter = iter(testLoader)\n",
        "images, labels = testiter.next()\n",
        "\n",
        "#跑測試集預測\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    pred = model(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aP0iTdwS-85"
      },
      "outputs": [],
      "source": [
        "images_np = [i.cpu() for i in images] #把圖片轉成矩陣\n",
        "class_names = celeba_data.classes  #儲存['no_smile', 'smile']兩個標籤東西\n",
        "print(class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw-EQAACS-_G"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(15, 7))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "for i in range(64):\n",
        "    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(images_np[i].permute(1,2,0)) \n",
        "    #permute為根據原本[0][1][2]的大小排成需要的樣子\n",
        "    #像是images_np[i]為(3,256,256)經(1,2,0)轉換後會變成(256,256,3)\n",
        "\n",
        "    if labels[i] == torch.max(pred[i], 0)[1]: #torch.max 出來會有兩組數字，取第1組才是預測出來的標籤\n",
        "        ax.text(0, 8, class_names[torch.max(pred[i], 0)[1]], color='blue',size=20)\n",
        "    else:\n",
        "        ax.text(0, 8, class_names[torch.max(pred[i], 0)[1]], color='red',size=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApTEbrF4S_BX"
      },
      "outputs": [],
      "source": [
        "#測試自己的單張圖片\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from torch.autograd import Variable as V\n",
        "import torch as t\n",
        "\n",
        "#讀入圖片\n",
        "img = Image.open('data/瑞宏.png')  #換另一張 瑞宏.png\n",
        "img = img.resize((256, 256))\n",
        "plt.imshow(img)\n",
        "\n",
        "transf = transforms.ToTensor()\n",
        "iminput = transf(img)  # tensor数据格式是torch(C,H,W)\n",
        "\n",
        "iminput = iminput.unsqueeze(0)#增加一維，輸出的img格式爲[1,C,H,W]\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    iminput = V(iminput.cuda())\n",
        "    pred = model(iminput)#將圖片輸入網絡得到輸出\n",
        "    print(pred)\n",
        "    if torch.max(pred[0],0)[1] == 1:\n",
        "        print(\"有笑\")\n",
        "    else:\n",
        "        print(\"沒笑\")\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyLU-KuQS_Di"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGusRotYS_F3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6PZu/lqTNaJeQdh0lYbjx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}